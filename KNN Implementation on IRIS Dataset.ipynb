{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: KNN Implementation\n",
    "# Author: Rishabh Malhotra\n",
    "# All Rights Reserved by Datum Guy & the Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for data input operation for csv file. \n",
    "# Parmeters: \n",
    "## Filepath - Path of the csv file on the system\n",
    "## COLS - Number of columns present in the csv. Default is 5.\n",
    "# Returns:\n",
    "## List - This List Contains a list of all the input variables values, list of output values, list of mean for all input \n",
    "## variables and list of standard deviation for all input variables.\n",
    "\n",
    "def get_data(filepath,COLS = 5):\n",
    "    # Opens the file handler for the dataset file. Using variable 'f' we can access and manipulate our file anywhere \n",
    "    # in our code after the next code line.\n",
    "    f = open(filepath,\"r\")\n",
    "\n",
    "    # This list will contain the header names (column names) for each column. If there are no header names for the dataset\n",
    "    # you can mark set header flag as False.\n",
    "    headers = []\n",
    "    header= False\n",
    "    \n",
    "    # Predictors Collection (or your input variable)\n",
    "    X = [[] for i in range(COLS-1)]\n",
    "\n",
    "    # Output Response (or your output variable)\n",
    "    Y = []\n",
    "\n",
    "    # Initializing a reader generator using reader method from csv module. A reader generator takes each line from the \n",
    "    # file and converts it into list of columns.\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Using for loop, we are able to read one row at a time.\n",
    "    for row in reader:\n",
    "        # if there is a header row in the dataset (i.e if the dataset contains column names as well we append them into headers list)\n",
    "        if header:\n",
    "            for i in range(0,COLS):\n",
    "                headers.append(row[i])\n",
    "            header = False\n",
    "        else:\n",
    "            # This section of the code extracts input variables values.\n",
    "            for i in range(0,COLS-1):\n",
    "                X[i].append(float(row[i]))\n",
    "        \n",
    "        # This line of code helps in getting \n",
    "        Y.append(row[COLS-1])\n",
    "\n",
    "    # Close the file once we have succesffuly stored all data into our X and Y variables.\n",
    "    f.close()\n",
    "    \n",
    "    # Set this as True if you want to normalize the data, set False otherwise.\n",
    "    data_normalization = True\n",
    "    \n",
    "    if data_normalization:\n",
    "        # Normalization of Input Data.\n",
    "        mean = []\n",
    "        std = []\n",
    "        \n",
    "        # Calculation of mean and standard deviation for all input variables.\n",
    "        for i in range(0,COLS-1):\n",
    "            X[i] = np.array(X[i])\n",
    "            mean.append(np.mean(X[i]))\n",
    "            std.append(np.std(X[i]))\n",
    "    \n",
    "        # Returning Normalized Data\n",
    "        return [np.array([(X[i] - mean[i])/(std[i]) for i in range(0,4)]),np.array(Y),mean,std]\n",
    "    else:\n",
    "        return [np.array(X),np.array(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance - This is a similarity measure which depicts the distance between two points in N Dimensions.\n",
    "# Let's suppose you have two data points in 2 Dimensional plane A and B. Euclidean distance is the shortest distance \n",
    "# between A and B. \n",
    "# Illustrated in Fig-1\n",
    "def euclidean_distance(a,b):\n",
    "    distance = 0.0\n",
    "    for i in range(0,len(a)):\n",
    "        distance = distance + ((a[i]-b[i])**2)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig-1](../img/Fig-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Method using K-Nearest neighbour Technique\n",
    "def predict_using_KNN(TrainingData,NewData, k):\n",
    "    euclidean_distances_with_category = []\n",
    "    # Input Variables of Training Data \n",
    "    train_X = TrainingData[0]\n",
    "    \n",
    "    # Output Variable of Training Data\n",
    "    train_Y = TrainingData[1]\n",
    "    \n",
    "    # Calculating Euclidean Distance between unknown datapoint and all the datapoints in training data. \n",
    "    # For illustration see fig-2\n",
    "    # It is stored in a list of the following format:\n",
    "    # [\n",
    "    #   [2.35,\"Iris-Setosa\"], # Distance of Training Data Point-1 from Unknown Datapoint\n",
    "    #   [3.51,\"Iris-Virginica\"],# Distance of Training Data Point-2 from Unknown Datapoint\n",
    "    #   ......\n",
    "    # ]\n",
    "    for idx in range(0,train_X.shape[0]):\n",
    "        euclidean_distances_with_category.append([euclidean_distance(list(train_X[idx]),NewData),train_Y[idx]])\n",
    "        \n",
    "    # Sort euclidean Distance between all the data points in training data and unknown datapoint in increasing order\n",
    "    euclidean_distances_with_category.sort()\n",
    "    \n",
    "    # Return top k euclidean distance from the sorted collection. These are the k datapoints which are nearest to our \n",
    "    # unknown datapoint and depending their classes we will assign a class to unknown datapoint.\n",
    "    return euclidean_distances_with_category[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig-2](../img/Fig-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_order(X,Y):\n",
    "    # Create a ordered sequence upto length of rows present in dataset [1,2,3,4,5,........,N]\n",
    "    # where N - number of rows in dataset\n",
    "    randomize = np.arange(X.shape[0])\n",
    "    # Randomize (shuffle) the above list \n",
    "    np.random.shuffle(randomize)\n",
    "    \n",
    "    # Shuffle the X and Y collection accordingly.\n",
    "    X = X[randomize]\n",
    "    Y = Y[randomize]\n",
    "    \n",
    "    return [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Input Variables (X), Output Variable (Y), means of all input variables, standard deviations of all input variables.\n",
    "X,Y,mean,std = get_data(\"./Data/data.csv\",5)\n",
    "\n",
    "# Currently we have X in which the format is [[All values of input variable 1],[All Values of input variable 2],....]\n",
    "# BUT what we want the format of out X variable is - \n",
    "# [\n",
    "#  [All values of input variables for training data point 1],\n",
    "#  [All values of input variables for training data point 2],\n",
    "#  [All values of input variables for training data point 3],\n",
    "#  [All values of input variables for training data point 4],\n",
    "#  .....\n",
    "# ]\n",
    "# Thus we transpose our X array\n",
    "X = np.transpose(X)\n",
    "\n",
    "# In our iris dataset all the rows of iris-setosa are first 50 rows, then next 50 rows are for iris virginica and so on.\n",
    "# This makes it difficult for us to select one part of the dataset for training and other for testing.\n",
    "# To eliminate this we shuffle our original dataset randomly using random_order function we created.\n",
    "X,Y = random_order(X,Y)\n",
    "\n",
    "# This is the row at which we split our dataset as training and testing.\n",
    "# Ratio is the value of how much data you want to use as training dataset\n",
    "ratio = 0.8\n",
    "split_row = int(X.shape[0]*ratio)\n",
    "\n",
    "# Creating training dataset\n",
    "train_X = X[0:split_row]\n",
    "train_Y = Y[0:split_row]\n",
    "\n",
    "# Creating testing dataset\n",
    "test_X = X[split_row:]\n",
    "test_Y = Y[split_row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbour \"K\" Hyper Parameter\n",
    "k=10\n",
    "\n",
    "# Predictions for test dataset will be stored in pred_Y\n",
    "pred_Y = []\n",
    "\n",
    "# For all the rows present in testing dataset, using k nearest neighbor predict the class to which they belong.\n",
    "for idx in range(0,test_X.shape[0]):\n",
    "    tmp = []\n",
    "    \n",
    "    # Get top k euclidean distances (nearest training data points to current data point in testing dataset)\n",
    "    topKValues = predict_using_KNN([train_X,train_Y],test_X[idx],k)\n",
    "    \n",
    "    # Out of those k nearest data points, which class is most occuring in those data points and assign that class\n",
    "    # to the current testing data point.\n",
    "    for _k in range(0,k):\n",
    "        tmp.append(topKValues[_k][1])\n",
    "    pred_Y.append(stats.mode(tmp)[0][0])\n",
    "\n",
    "pred_Y = np.array(pred_Y)\n",
    "print(pred_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
